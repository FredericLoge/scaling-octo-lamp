# Writing efficient code


## Best R practice recommendations

- Cleanliness & tidyness: avoid data copy, avoid garbage names throughout code, treat your RAM with kindness

- Comments are mandatory, even if variable names are explicit

- Work under RProject

- If you wish to build something that should last (used by others, robust etc), developing as an R Package is mandatory. Not suitable when doing tutorials and trying a million different things though :/


## Timing

When you are writing an R function, measuring it's execution time is good practice.

```{r}
# define a function
foo <- function(){ return(sum(1:1e6)) }

# measure execution of the function, once
# user: actual CPU time for the process
# system: any indirect operation due to the process: I/O of files, GC, memory allocation, ...
# elapsed: total elapsed time
system.time({ foo() })

# repeat 50 times the function to get some statistics
microbenchmark::microbenchmark({ foo() }, times = 50)
```

## Profiling code

When your function (or general code) contains several instructions, profiling it allows you to see where exactly things go wrong. Here's a vanilla example:

```{r}
# note that in RStudio you can use the "Profile" menu identically
profvis::profvis({
  r <- c()
  s <- 0
  for(i in 1:1e6){
    s <- s + i
    r[i] <- i
  }
})
```

## Exercise: Moving Average

::: {.callout-note title='Moving Average'}

Input: x, numerical vector of length N

Output: y, numerical vector of same length, where $y_i := (x_i-1)+x_i+(x_i+1)/3$ if $i > 1$ and $i < N$, otherwise $y_i$ is NA.

Propose some implementations of this function and use the timing functions seen previously to time yourselves.

:::

## Solution(?)

```{r}
x <- rnorm(n=1e6)
n <- length(x)

ma_0 <- function(x, n){
  y <- rep(NA, n)
  for(i in (2:(n-1))){
    y[i] <- (x[i-1]+x[i]+x[i+1])/3
  }
  return(y)
}

ma_1 <- function(x, n){
  return((c(NA, x[1:(n-1)]) + x + c(x[2:n], NA))/3)
}

microbenchmark::microbenchmark(ma_0(x=x, n=n), ma_1(x=x, n=n))
```
**Vector** operations are a must-use resource of R.

## Why still create our own R functions ?

If it exists in R and ruins decently well, then why rebuild it ?

There are many cases were we might not find our pick:

- Data simulation purposes

- Statistical metrics

- Optimization functions

...

- Because we don't know any other language ðŸ˜­


## Exercise: Simulation Example

::: {.callout-note title='Simulation'}

Consider the following dynamic system:

- $x_0$ is in $[0;1]$

- $\lambda$ is in $[0;4]$

Then, for all $t \geq 1$:

$x_t = \lambda * x_{t-1} * (1 - x_{t-1})$.

Step 1. Code an R function which takes as input $(x_0, \lambda, n)$ and returns output $x_n$.

Step 2. Run the function for a uniform grid of $(x_0, \lambda)$, the size of your choosing.

:::


## Solution to step 1

```{r}
library(Rcpp)

run_iteration <- function(n_iter, x0, lambda){
  for(i in 1:n_iter){
    x0 <- lambda * x0 * (1-x0)
  }
  return(x0)
}

cppFunction("
          double run_iteration_cpp(int n_iter, double x0, double lambda) {
            for (int i = 0; i < n_iter; i++) {
              x0 = lambda * x0 * (1.0 - x0);
            }
            return x0;
          }
        ")

microbenchmark::microbenchmark(run_iteration(n_iter=1e6, x=0.5, lambda=3.8), run_iteration_cpp(n_iter=1e6, x=0.5, lambda=3.8))
```

## Solution to step 2 - plot

See more info on this [over here](https://en.wikipedia.org/wiki/Feigenbaum_constants). 

```{r, echo=FALSE}
n_x0 = 100
n_lambda = 100
mat = matrix(data=NA, nrow=n_x0*n_lambda, ncol=3)
row_idx = 1
for(x0 in runif(n=n_x0, min=0, max=1)){
  for(lambda in runif(n=n_lambda, min=2, max=4)){
    r <- run_iteration_cpp(n_iter=100, x0=x0, lambda=lambda)
    mat[row_idx,] <- c(x0, lambda, r)
    row_idx <- row_idx+1
  }
}

plot(
  x=mat[,2], 
  y=mat[,3], 
  pch='.', 
  xlab=expression(lambda), 
  ylab=expression(x[t]),
  cex.axis=2,
  cex.lab=2,
  cex.main=2,
  main='Bifurcation Diagram'
)
```

## Memory

Aside from time benchmarks, scanning our environment for large objects can always be useful.

- `ls()` provides you the list of elements in your env

- `object.size(<the element>)` gives you its size (also ``lobstr::obj_size(<the element)``)

- `rm()` removes an object from the env

- `gc()` runs garbage collection (which runs periodically anyway so no need usually)


## Why do we need garbage collection ?

- RHS data is created and bounded to one or more names
- When a modification on RHS is requested, a copy is made. 
- When an element is removed from the environment, it removes the name and its bind to the value, but the value in memory is still taken, until the garbage collector does its job.

```{r}
a <- c(1, 2, 3)
b <- a # make copy

print(lobstr::obj_addr(a))
print(lobstr::obj_addr(b))

b[1] <- 0

print(lobstr::obj_addr(a))
print(lobstr::obj_addr(b))
```

## Exercise: Order of Magnitude

::: {.callout-note title='Order of Magnitude'}

Generate random datasets:

- vary the data types: numerical, boolean, categorical

- vary the number of observations and columns

For each dataset generated, compute the object size and make a nice visualization from it
:::

## Solution (?)

```{r}
n <- 1e6

vec_1_million <- rnorm(n=n)
print(lobstr::obj_size(vec_1_million))

binary_vec_1_million <- round(rnorm(n=n))
print(lobstr::obj_size(binary_vec_1_million))

char_vec_1_million <- as.character(rnorm(n=n))
print(lobstr::obj_size(char_vec_1_million))
```
Conclusion ?

## To confuse you:
```{r}
char_vec_1_million <- as.character(rnorm(n=n))
print(lobstr::obj_size(char_vec_1_million))

toto <- list(char_vec_1_million, char_vec_1_million, char_vec_1_million)
print(lobstr::obj_size(toto))

toto[[1]][1] <- 9
print(lobstr::obj_size(toto))

banana <- "bananas bananas bananas"
print(lobstr::obj_size(banana))
print(lobstr::obj_size(rep(banana, 100)))
```

## Take-Home Exercises

- Write an efficient ifelse block statement taking as input a numerical vector, with the conditions of your choice

- Investigate confusing memory examples in slide above

- Rcpp implementation of optimization function e.g. Decision Tree
